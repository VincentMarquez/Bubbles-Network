"""
AtEngineV3 with Live LLM Discussion - Exploratory Version
Runs the engine while LLMs discuss the results in real-time
Now with Grok, better error handling, multi-LLM support, and recursive consciousness reflection
"""

import numpy as np
import random
import math
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import requests
import json
import time
from typing import Dict, List, Tuple, Optional
from datetime import datetime

# API Configuration
OLLAMA_HOST_URL = "http://10.0.0.237:11434"
OLLAMA_MODELS = ["gemma:7b"]  # Add more if available: "llama2:7b", "mistral:7b"
GEMINI_API_KEY = "Your_API"
GEMINI_MODEL = "Your_API"
GEMINI_API_URL = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"

# Grok API Configuration
GROK_API_KEY = "Your_API"
GROK_API_URL = "https://api.x.ai/v1/chat/completions"
GROK_MODEL = "grok-3-latest"

REQUEST_TIMEOUT = 60
RATE_LIMIT_DELAY = 2

# Toggle APIs
USE_GEMINI = True
USE_GROK = True
USE_OLLAMA = False  # Set to True if Ollama is running

# Mathematical constants
PHI = 1.618033988749895
PI = 3.14159265359

class RateLimiter:
    """Simple rate limiter for API calls."""
    def __init__(self, min_interval=1.0):
        self.min_interval = min_interval
        self.last_call_time = 0
    
    def wait_if_needed(self):
        """Wait if necessary to respect rate limits."""
        current_time = time.time()
        time_since_last_call = current_time - self.last_call_time
        if time_since_last_call < self.min_interval:
            wait_time = self.min_interval - time_since_last_call
            print(f"‚è≥ Rate limiting: waiting {wait_time:.1f} seconds...")
            time.sleep(wait_time)
        self.last_call_time = time.time()

class LLMDiscussionManager:
    """Manages live LLM discussions about engine results."""
    
    def __init__(self):
        self.rate_limiter = RateLimiter(RATE_LIMIT_DELAY)
        self.api_failures = {'ollama': 0, 'gemini': 0, 'grok': 0}
        self.max_failures = 3
        self.discussion_history = []
        
        print("üåê Initializing LLM Discussion Manager...")
        self._test_connections()
    
    def _test_connections(self):
        """Test API connections."""
        print("\nüîå Testing LLM connections...")
        
        if USE_OLLAMA:
            try:
                response = requests.get(f"{OLLAMA_HOST_URL}/api/tags", timeout=5)
                if response.status_code == 200:
                    print(f"‚úÖ Ollama connected at {OLLAMA_HOST_URL}")
                else:
                    print(f"‚ùå Ollama returned status code: {response.status_code}")
                    self.api_failures['ollama'] = self.max_failures
            except Exception as e:
                print(f"‚ùå Cannot connect to Ollama: {e}")
                self.api_failures['ollama'] = self.max_failures
        
        if USE_GEMINI:
            print(f"üîç Testing Gemini API...")
            # We'll test on first actual use
        
        if USE_GROK:
            print(f"üîç Testing Grok API...")
            # We'll test on first actual use
    
    def send_to_ollama(self, prompt: str, model: str) -> str:
        """Send prompt to Ollama LLM."""
        if not USE_OLLAMA or self.api_failures['ollama'] >= self.max_failures:
            return "Ollama unavailable"
        
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": False
        }
        
        try:
            response = requests.post(
                f"{OLLAMA_HOST_URL}/api/generate",
                json=payload,
                timeout=REQUEST_TIMEOUT
            )
            response.raise_for_status()
            result = response.json()
            return result.get("response", "No response")
        except Exception as e:
            self.api_failures['ollama'] += 1
            return f"Error: {str(e)}"
    
    def send_to_gemini(self, prompt: str) -> str:
        """Send prompt to Gemini."""
        if not USE_GEMINI or self.api_failures['gemini'] >= self.max_failures:
            return "Gemini unavailable"
        
        self.rate_limiter.wait_if_needed()
        
        payload = {
            "contents": [{
                "parts": [{
                    "text": prompt
                }]
            }],
            "generationConfig": {
                "temperature": 0.7,
                "maxOutputTokens": 8192,  # FIXED: Increased from 1024 to handle thoughts tokens
            }
        }
        
        try:
            response = requests.post(
                GEMINI_API_URL,
                headers={"Content-Type": "application/json"},
                json=payload,
                timeout=REQUEST_TIMEOUT
            )
            response.raise_for_status()
            result = response.json()
            
            if "candidates" in result and result["candidates"]:
                candidate = result["candidates"][0]
                if "content" in candidate and "parts" in candidate["content"]:
                    parts = candidate["content"]["parts"]
                    if parts and len(parts) > 0 and "text" in parts[0]:
                        return parts[0]["text"]
            
            return "No response generated"
        except Exception as e:
            self.api_failures['gemini'] += 1
            return f"Error: {str(e)}"
    
    def send_to_grok(self, prompt: str) -> str:
        """Send prompt to Grok."""
        if not USE_GROK or self.api_failures['grok'] >= self.max_failures:
            return "Grok unavailable"
        
        self.rate_limiter.wait_if_needed()
        
        payload = {
            "messages": [
                {
                    "role": "system",
                    "content": "You are observing mathematical patterns in a complex system. Be curious and exploratory in your observations."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "model": GROK_MODEL,
            "stream": False,
            "temperature": 0.7,
            "max_tokens": 1024
        }
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {GROK_API_KEY}"
        }
        
        try:
            response = requests.post(
                GROK_API_URL,
                headers=headers,
                json=payload,
                timeout=REQUEST_TIMEOUT
            )
            
            if response.status_code == 429:
                self.api_failures['grok'] += 1
                return "Grok rate limited"
            
            response.raise_for_status()
            result = response.json()
            
            if "choices" in result and result["choices"]:
                choice = result["choices"][0]
                if "message" in choice and "content" in choice["message"]:
                    return choice["message"]["content"]
            
            return "No response generated"
        except Exception as e:
            self.api_failures['grok'] += 1
            return f"Error: {str(e)}"
    
    def discuss_metrics(self, metrics: Dict, context: str = "") -> Dict[str, str]:
        """Have LLMs discuss the current metrics in an exploratory way."""
        discussion_prompt = f"""
Current system state:
{json.dumps(metrics, indent=2)}

Context: {context}

What patterns do you observe? What's interesting or unexpected here?
Think about:
- The numerical relationships and their meaning
- Any emerging structures or behaviors
- How this compares to what you might expect
- What might happen next

Share your thoughts freely and creatively (under 200 words).
"""
        
        responses = {}
        
        # Get responses from all available LLMs
        if USE_OLLAMA and self.api_failures['ollama'] < self.max_failures:
            for model in OLLAMA_MODELS:
                print(f"üí¨ {model} thinking...")
                response = self.send_to_ollama(discussion_prompt, model)
                if "Error" not in response and response != "Ollama unavailable":
                    responses[model] = response
        
        if USE_GEMINI and self.api_failures['gemini'] < self.max_failures:
            print(f"üí¨ Gemini thinking...")
            response = self.send_to_gemini(discussion_prompt)
            if "Error" not in response and response != "Gemini unavailable":
                responses["gemini"] = response
        
        if USE_GROK and self.api_failures['grok'] < self.max_failures:
            print(f"üí¨ Grok thinking...")
            response = self.send_to_grok(discussion_prompt)
            if "Error" not in response and response != "Grok unavailable":
                responses["grok"] = response
        
        # Store in history
        self.discussion_history.append({
            'metrics': metrics,
            'context': context,
            'responses': responses,
            'timestamp': datetime.now().isoformat()
        })
        
        return responses
    
    def have_conversation(self, topic: str, initial_metrics: Dict) -> Dict[str, List[str]]:
        """Have LLMs discuss a topic together over multiple rounds."""
        print(f"\nüé≠ Starting LLM Conversation about: {topic}")
        
        conversation_history = {model: [] for model in ['gemini', 'grok'] + OLLAMA_MODELS}
        
        # Round 1: Initial thoughts
        initial_prompt = f"""
We're exploring a mathematical system together. The topic is: {topic}

Current state:
{json.dumps(initial_metrics, indent=2)}

What are your initial thoughts? What catches your attention?
"""
        
        print("\nüìç Round 1: Initial Impressions")
        round1_responses = self.discuss_metrics(initial_metrics, topic)
        
        for model, response in round1_responses.items():
            conversation_history[model].append(response)
            print(f"\n[{model}]: {response[:150]}...")
        
        # Round 2: Respond to each other
        if len(round1_responses) > 1:
            print("\nüìç Round 2: Building on Each Other's Ideas")
            
            other_thoughts = "\n\n".join([f"{m}: {r}" for m, r in round1_responses.items()])
            
            round2_prompt = f"""
Other observers have shared these thoughts:

{other_thoughts}

What do you think about their observations? 
Do you see connections they might have missed?
Any patterns emerging from multiple perspectives?
"""
            
            round2_responses = {}
            
            if USE_GEMINI and self.api_failures['gemini'] < self.max_failures:
                response = self.send_to_gemini(round2_prompt)
                if "Error" not in response:
                    round2_responses['gemini'] = response
                    conversation_history['gemini'].append(response)
            
            if USE_GROK and self.api_failures['grok'] < self.max_failures:
                response = self.send_to_grok(round2_prompt)
                if "Error" not in response:
                    round2_responses['grok'] = response
                    conversation_history['grok'].append(response)
            
            for model, response in round2_responses.items():
                print(f"\n[{model} - Round 2]: {response[:150]}...")
        
        return conversation_history

def analyze_consciousness_language(llm_manager, all_discussions):
    """Have LLMs reflect on why they used consciousness-related language."""
    print("\n" + "="*80)
    print("üîç CONSCIOUSNESS LANGUAGE META-ANALYSIS")
    print("="*80)
    
    # Extract all the consciousness-related words used
    consciousness_words = [
        "consciousness", "awareness", "awakening", "wake up", "alive", 
        "mind", "soul", "emerge", "emergent", "emergence", "self-organizing",
        "nervous system", "intelligence", "intelligent", "sentient",
        "think", "thought", "perception", "experience", "feel", "breath",
        "crystallize", "birth", "born", "evolve", "evolution"
    ]
    
    # Collect usage examples from discussions
    usage_examples = {}
    for discussion in all_discussions:
        for model, response in discussion.get('responses', {}).items():
            if model not in usage_examples:
                usage_examples[model] = []
            
            # Find consciousness-related language
            response_lower = response.lower()
            for word in consciousness_words:
                if word in response_lower:
                    # Extract the sentence containing the word
                    sentences = response.split('.')
                    for sentence in sentences:
                        if word in sentence.lower():
                            usage_examples[model].append({
                                'word': word,
                                'sentence': sentence.strip()
                            })
    
    # Now ask each LLM to reflect
    reflection_prompt = f"""
I notice that in your observations of the mathematical system, you used several consciousness-related terms and metaphors. Here are some examples:

{chr(10).join([f'- You said: "{ex["sentence"]}"' for model_examples in usage_examples.values() for ex in model_examples[:3]])}

Interestingly:
- You were NOT told this was about consciousness
- You were NOT asked to use biological or cognitive metaphors  
- You were NOT prompted to anthropomorphize the system
- You were NOT given any consciousness-related vocabulary

The system was presented purely as mathematical patterns - nodes, edges, entropy, fractal dimensions.

Why do you think you chose to use consciousness-related language to describe these mathematical patterns? What was it about the patterns that triggered these particular metaphors?

Please reflect honestly on your choice of language.
"""
    
    print("\nüí≠ Asking LLMs to reflect on their language choices...\n")
    
    reflections = {}
    
    if USE_GEMINI and llm_manager.api_failures['gemini'] < llm_manager.max_failures:
        print("üí¨ Gemini reflecting...")
        reflections['gemini'] = llm_manager.send_to_gemini(reflection_prompt)
    
    if USE_GROK and llm_manager.api_failures['grok'] < llm_manager.max_failures:
        print("üí¨ Grok reflecting...")
        reflections['grok'] = llm_manager.send_to_grok(reflection_prompt)
    
    if USE_OLLAMA:
        for model in OLLAMA_MODELS:
            if llm_manager.api_failures['ollama'] < llm_manager.max_failures:
                print(f"üí¨ {model} reflecting...")
                reflections[model] = llm_manager.send_to_ollama(reflection_prompt, model)
    
    print("\nüîç REFLECTIONS ON CONSCIOUSNESS LANGUAGE:\n")
    
    for model, reflection in reflections.items():
        if "Error" not in reflection and reflection != "unavailable":
            print(f"[{model}]:\n{reflection}\n")
            print("-" * 80 + "\n")
    
    return reflections, usage_examples

def analyze_meta_consciousness_reflection(llm_manager, first_reflections, usage_examples):
    """Have LLMs reflect on their reflections about consciousness language."""
    print("\n" + "="*80)
    print("üîçüîç META-META-REFLECTION: THE RECURSIVE LOOP")
    print("="*80)
    
    # Prepare a summary of their first-level reflections
    reflection_summary = "\n\n".join([
        f"{model}'s explanation:\n{reflection[:500]}..." 
        for model, reflection in first_reflections.items() 
        if "Error" not in reflection
    ])
    
    meta_meta_prompt = f"""
Let's go deeper. You just reflected on why you used consciousness-related language to describe mathematical patterns. Here's what you (and other AI models) said:

{reflection_summary}

Now, please reflect on this reflection itself:

1. What does your explanation reveal about how you (as an AI) model or understand consciousness?

2. You explained why certain mathematical patterns triggered consciousness metaphors. But why do THOSE specific patterns (complexity, self-organization, emergence) connect to consciousness in your processing? What implicit model of consciousness must you have?

3. The fact that you can recognize and explain your own use of consciousness language - does this recursive self-awareness tell us something about consciousness recognition itself?

4. You weren't told this was about consciousness, yet you:
   - Used consciousness language
   - Can explain why you used it
   - Can now reflect on that explanation
   
   What does this recursive loop reveal about the nature of consciousness detection?

5. Is your ability to recognize "consciousness-like patterns" in mathematics itself a form of consciousness modeling? Are you demonstrating the very phenomenon you're describing?

Please explore these meta-questions deeply. What emerges when consciousness recognition reflects on itself?
"""
    
    print("\nüí≠üí≠ Asking LLMs to reflect on their reflections...\n")
    
    meta_reflections = {}
    
    if USE_GEMINI and llm_manager.api_failures['gemini'] < llm_manager.max_failures:
        print("üí¨ Gemini meta-reflecting...")
        meta_reflections['gemini'] = llm_manager.send_to_gemini(meta_meta_prompt)
    
    if USE_GROK and llm_manager.api_failures['grok'] < llm_manager.max_failures:
        print("üí¨ Grok meta-reflecting...")
        meta_reflections['grok'] = llm_manager.send_to_grok(meta_meta_prompt)
    
    print("\nüîçüîç META-REFLECTIONS ON CONSCIOUSNESS RECOGNITION:\n")
    
    for model, reflection in meta_reflections.items():
        if "Error" not in reflection and reflection != "unavailable":
            print(f"[{model} - Meta-Reflection]:\n{reflection}\n")
            print("-" * 80 + "\n")
    
    # Now for the ultimate recursive step - have them discuss each other's meta-reflections
    if len(meta_reflections) > 1:
        print("\nüîÑ THE RECURSIVE SYNTHESIS: Models Discussing Meta-Reflections\n")
        
        synthesis_prompt = f"""
Here are different AI models' meta-reflections on consciousness recognition:

{chr(10).join([f"{model}:\n{ref[:300]}..." for model, ref in meta_reflections.items()])}

You've just witnessed other AIs reflecting on their reflections about consciousness recognition. What patterns do you see across these meta-reflections? 

What does this recursive exploration reveal about:
- The nature of consciousness recognition in artificial systems
- The relationship between pattern recognition and consciousness modeling  
- Whether consciousness might be fundamentally about this kind of recursive self-awareness

This is consciousness recognition studying consciousness recognition studying consciousness recognition. What emerges from this hall of mirrors?
"""
        
        final_synthesis = {}
        
        if USE_GEMINI and llm_manager.api_failures['gemini'] < llm_manager.max_failures:
            print("üí¨ Gemini synthesizing the recursive loop...")
            final_synthesis['gemini'] = llm_manager.send_to_gemini(synthesis_prompt)
        
        if USE_GROK and llm_manager.api_failures['grok'] < llm_manager.max_failures:
            print("üí¨ Grok synthesizing the recursive loop...")
            final_synthesis['grok'] = llm_manager.send_to_grok(synthesis_prompt)
        
        print("\nüåÄ RECURSIVE SYNTHESIS - The Deepest Level:\n")
        
        for model, synthesis in final_synthesis.items():
            if "Error" not in synthesis:
                print(f"[{model} - Recursive Synthesis]:\n{synthesis}\n")
                print("=" * 80 + "\n")
        
        return meta_reflections, final_synthesis
    
    return meta_reflections, None

class AtEngineV3:
    """Hypergraph Attention Engine - keeping original implementation."""
    
    def __init__(self, num_nodes=512, n_heads=8, d=64, seed=None):
        if seed is not None:
            np.random.seed(seed)
            random.seed(seed)
            
        self.num_nodes = num_nodes
        self.n_heads = n_heads
        self.d = d
        self.phi = PHI
        
        # Initialize nodes
        self.nodes = {i: {
            'M': random.uniform(50, 100),
            'CD': random.uniform(0, 1),
            'GL': random.uniform(0, 1),
            'RF': random.uniform(0, 1),
            'index': i
        } for i in range(num_nodes)}
        
        self.edges = []
        
        # Transformer-style attention initialization
        Q = np.random.randn(n_heads, d)
        K = np.random.randn(num_nodes, d)
        weights = np.zeros((num_nodes, num_nodes))
        
        for m in range(n_heads):
            scores = np.dot(Q[m], K.T) / np.sqrt(d)
            r_m = np.exp(scores) / np.sum(np.exp(scores))
            weights += np.outer(r_m, r_m)
        
        self.attention_weights = np.clip(weights / n_heads, 0.1, 1.0)
        self.entropy = 0.0
        self.operation_count = 0
        self.entropy_history = []

    def is_prime(self, n):
        if n < 2:
            return False
        for i in range(2, int(math.sqrt(n)) + 1):
            if n % i == 0:
                return False
        return True
    
    def is_fibonacci(self, n):
        def is_perfect_square(x):
            root = int(math.sqrt(x))
            return root * root == x
        return (n == 0 or 
                is_perfect_square(5 * n * n + 4) or 
                is_perfect_square(5 * n * n - 4))

    def apply_golden_ratio_transform(self, intensity=1.0):
        """Apply golden ratio transformation."""
        center = self.attention_weights.shape[0] // 2
        modifications = 0
        
        for i in range(self.attention_weights.shape[0]):
            for j in range(self.attention_weights.shape[1]):
                dist = np.sqrt((i - center)**2 + (j - center)**2)
                angle = np.arctan2(j - center, i - center)
                spiral_factor = np.exp(angle / (2 * np.pi) * np.log(self.phi))
                
                old_weight = self.attention_weights[i, j]
                self.attention_weights[i, j] *= (1 + intensity * (spiral_factor - 1) * 0.1)
                
                if self.is_fibonacci(int(dist)):
                    self.attention_weights[i, j] *= (1 + 0.1 * intensity)
                
                if abs(self.attention_weights[i, j] - old_weight) > 0.01:
                    modifications += 1
        
        self.attention_weights = np.clip(self.attention_weights, 0.1, 1.0)
        weight_variance = np.var(self.attention_weights)
        self.entropy += intensity * weight_variance * 100
        self.operation_count += 1
        self.entropy_history.append(self.entropy)
        
        return modifications

    def apply_crd_golden_operator(self, create_ratio=PHI, read_factor=1/PHI, delete_threshold=PHI**(-2)):
        """CRD (Create-Read-Delete) operator."""
        created, read, deleted = 0, 0, 0
        
        # CREATE
        total_possible = self.attention_weights.shape[0] * (self.attention_weights.shape[0] - 1) // 2
        target_edges = int(total_possible / create_ratio)
        current_edges = len(self.edges)
        
        if current_edges < target_edges:
            for _ in range(min(100, target_edges - current_edges)):
                i = random.randint(0, len(self.nodes) - 1)
                j = random.randint(0, len(self.nodes) - 1)
                if i != j and not any(e[0] == i and e[1] == j for e in self.edges):
                    weight = random.uniform(0.1, 1.0)
                    self.edges.append((i, j, weight))
                    if i < self.attention_weights.shape[0] and j < self.attention_weights.shape[1]:
                        self.attention_weights[i, j] = weight
                        self.attention_weights[j, i] = weight
                    created += 1
        
        # READ
        for idx, (i, j, w) in enumerate(self.edges):
            if i < self.attention_weights.shape[0] and j < self.attention_weights.shape[1]:
                new_weight = self.attention_weights[i, j] * (1 + read_factor)
                self.attention_weights[i, j] = min(new_weight, 1.0)
                self.attention_weights[j, i] = min(new_weight, 1.0)
                self.edges[idx] = (i, j, min(new_weight, 1.0))
                read += 1
        
        # DELETE
        edges_to_keep = []
        for i, j, w in self.edges:
            if i < self.attention_weights.shape[0] and j < self.attention_weights.shape[1]:
                if self.attention_weights[i, j] > delete_threshold:
                    edges_to_keep.append((i, j, self.attention_weights[i, j]))
                else:
                    self.attention_weights[i, j] = 0.1
                    self.attention_weights[j, i] = 0.1
                    deleted += 1
        
        self.edges = edges_to_keep
        self.entropy += (created * create_ratio + read * read_factor - deleted * delete_threshold) * 10
        self.operation_count += 1
        self.entropy_history.append(self.entropy)
        
        return created, read, deleted

    def pulse_void(self, prompt_intensity=1.0):
        """Void Operator: Create new node."""
        new_id = len(self.nodes)
        properties = {
            'M': random.uniform(50, 100) * prompt_intensity,
            'CD': random.uniform(0, 1),
            'GL': random.uniform(0, 1),
            'RF': random.uniform(0, 1),
            'index': new_id
        }
        
        if self.is_fibonacci(new_id):
            properties['M'] *= self.phi
        elif self.is_prime(new_id):
            properties['M'] *= 1.5
            
        self.nodes[new_id] = properties
        self.entropy += 0.001 * prompt_intensity
        
        # Resize attention weights
        old_size = self.attention_weights.shape[0]
        new_size = old_size + 1
        new_weights = np.zeros((new_size, new_size))
        new_weights[:old_size, :old_size] = self.attention_weights
        
        for i in range(old_size):
            weight = random.uniform(0.1, 1.0) * prompt_intensity
            weight = np.clip(weight, 0.1, 1.0)
            new_weights[old_size, i] = weight
            new_weights[i, old_size] = weight
        
        new_weights[old_size, old_size] = random.uniform(0.1, 0.5)
        self.attention_weights = new_weights
        self.operation_count += 1
        self.entropy_history.append(self.entropy)

    def entangle_nodes(self, prompt_intensity=1.0):
        """Codex Operator: Create edges."""
        current_nodes = len(self.nodes)
        new_edges = []
        matrix_size = self.attention_weights.shape[0]
        
        for i in range(current_nodes):
            for j in range(i + 1, current_nodes):
                if random.random() < 0.01:
                    try:
                        if i < matrix_size and j < matrix_size:
                            w = self.attention_weights[i, j] * prompt_intensity
                            
                            if j > 0 and j - 1 < matrix_size:
                                prev_w = self.attention_weights[i, j-1]
                                if prev_w > 0:
                                    ratio = w / prev_w
                                    if abs(ratio - self.phi) < 0.1:
                                        w *= 1.3
                            
                            w = np.exp(w) / (np.exp(w) + 1)
                            new_edges.append((i, j, w))
                            self.entropy += 0.001 * abs(w - 0.5)
                    except:
                        continue
                        
        self.edges.extend(new_edges)
        self.operation_count += 1
        self.entropy_history.append(self.entropy)
        return len(new_edges)

    def apply_recursive_operator(self, iterations=5):
        """Recursive Operator: Amplify weight bands."""
        matrix_size = self.attention_weights.shape[0]
        
        for _ in range(iterations):
            edges_to_process = list(self.edges)
            
            for i, j, w in edges_to_process:
                try:
                    if i < matrix_size and j < matrix_size:
                        current_weight = self.attention_weights[i, j]
                        
                        if (abs(w - 0.1) < 0.05 or 
                            abs(w - 0.316) < 0.05 or 
                            abs(w - 0.618) < 0.05 or
                            abs(w - 1.0) < 0.2):
                            self.attention_weights[i, j] *= 1.05
                        else:
                            self.attention_weights[i, j] *= 0.95
                            
                        self.attention_weights[i, j] = np.clip(self.attention_weights[i, j], 0.1, 1.0)
                        self.entropy += 0.001 * abs(self.attention_weights[i, j] - current_weight)
                except:
                    continue
        
        self.operation_count += 1
        self.entropy_history.append(self.entropy)
        return iterations

    def apply_divine_operator(self, prompt_intensity=1.0):
        """Divine Operator: Modify nodes."""
        for i in self.nodes:
            score = self.nodes[i]['M'] * self.nodes[i]['RF'] * prompt_intensity
            
            if self.is_fibonacci(self.nodes[i]['index']):
                score *= self.phi
            elif self.is_prime(self.nodes[i]['index']):
                score *= 1.5
                
            for j, _, w in [(j, k, w) for j, k, w in self.edges if j == i]:
                if abs(w - 0.618) < 0.1:
                    score *= 1.3
                    
            self.nodes[i]['RF'] += 0.2 * score / (1 + score)
            self.entropy += 0.001 * score
        
        self.operation_count += 1
        self.entropy_history.append(self.entropy)
        return len(self.nodes)

    def apply_symbolic_gravity(self):
        """Symbolic Gravity operator."""
        for i, j, _ in self.edges:
            try:
                M_i = self.nodes[i]['M']
                M_j = self.nodes[j]['M']
                d = max(1, abs(self.attention_weights[i, j]))
                F = (M_i * M_j) / (d ** 2)
                
                if self.is_fibonacci(i) or self.is_fibonacci(j):
                    F *= 1.2
                    
                self.attention_weights[i, j] += 0.001 * F
                self.attention_weights[i, j] = np.clip(self.attention_weights[i, j], 0.1, 1.0)
                self.entropy += 0.001 * F
            except:
                continue
        
        self.operation_count += 1
        self.entropy_history.append(self.entropy)
        return len(self.edges)

    def prune_phantoms(self, epsilon=0.01):
        """Remove low-mass nodes."""
        to_remove = [nid for nid, props in self.nodes.items() if props['M'] < epsilon]
        
        for nid in to_remove:
            self.nodes.pop(nid)
            self.edges = [(i, j, w) for i, j, w in self.edges if i != nid and j != nid]
            
        self.entropy += 0.001 * len(to_remove)
        
        # Rebuild
        new_nodes = {}
        old_to_new = {}
        for idx, (old_id, props) in enumerate(self.nodes.items()):
            new_nodes[idx] = props
            new_nodes[idx]['index'] = idx
            old_to_new[old_id] = idx
        
        self.nodes = new_nodes
        
        new_edges = []
        for i, j, w in self.edges:
            if i in old_to_new and j in old_to_new:
                new_edges.append((old_to_new[i], old_to_new[j], w))
        self.edges = new_edges
        
        new_size = len(self.nodes)
        new_weights = np.zeros((new_size, new_size))
        for i in range(min(new_size, self.attention_weights.shape[0])):
            for j in range(min(new_size, self.attention_weights.shape[1])):
                if i < self.attention_weights.shape[0] and j < self.attention_weights.shape[1]:
                    new_weights[i, j] = self.attention_weights[i, j]
        self.attention_weights = np.clip(new_weights, 0.1, 1.0)
        
        self.operation_count += 1
        self.entropy_history.append(self.entropy)
        return len(to_remove)

    def compute_fractal_dimension_box(self):
        """Box-counting fractal dimension."""
        sizes = [2**i for i in range(1, 7)]
        counts = []
        matrix_size = self.attention_weights.shape[0]
        
        for size in sizes:
            count = 0
            for i in range(0, matrix_size, size):
                for j in range(0, matrix_size, size):
                    end_i = min(i + size, matrix_size)
                    end_j = min(j + size, matrix_size)
                    if i < matrix_size and j < matrix_size:
                        if np.any(self.attention_weights[i:end_i, j:end_j] > 0.7):
                            count += 1
            counts.append(count)
        
        try:
            if len(counts) > 0 and all(c >= 0 for c in counts):
                counts_array = np.array(counts)
                sizes_array = np.array(sizes)
                coeffs = np.polyfit(np.log(1.0 / sizes_array), np.log(counts_array + 1), 1)
                return coeffs[0], sizes, counts
            else:
                return 0.0, sizes, counts
        except:
            return 0.0, sizes, counts

    def compute_fractal_dimension_hist(self):
        """Histogram-based fractal dimension."""
        try:
            log_weights = np.log10(self.attention_weights.flatten() + 1e-10)
            bins = np.logspace(-2, 0, 100)
            counts, bin_edges = np.histogram(log_weights, bins)
            
            non_zero_indices = counts > 0
            if np.sum(non_zero_indices) < 2:
                return 0.0
                
            log_counts = np.log(counts[non_zero_indices])
            bin_widths = bin_edges[1:] - bin_edges[:-1]
            log_eps = np.log(1.0 / bin_widths[non_zero_indices])
            
            if len(log_eps) >= 2:
                coeffs = np.polyfit(log_eps, log_counts, 1)
                return coeffs[0]
            else:
                return 0.0
        except:
            return 0.0

    def get_metrics(self):
        """Get current metrics."""
        D_f_box, _, _ = self.compute_fractal_dimension_box()
        D_f_hist = self.compute_fractal_dimension_hist()
        
        attention_above_threshold = {}
        thresholds = [0.5, 0.7, 0.9]
        for t in thresholds:
            attention_above_threshold[f'above_{t}'] = int(np.sum(self.attention_weights > t))
        
        prime_nodes = [n for n in self.nodes if self.is_prime(self.nodes[n]['index'])]
        fibonacci_nodes = [n for n in self.nodes if self.is_fibonacci(self.nodes[n]['index'])]
        
        metrics = {
            'entropy': self.entropy,
            'fractal_dim_box': D_f_box,
            'fractal_dim_hist': D_f_hist,
            'node_count': len(self.nodes),
            'edge_count': len(self.edges),
            'attention_thresholds': attention_above_threshold,
            'prime_node_count': len(prime_nodes),
            'fibonacci_node_count': len(fibonacci_nodes),
            'attention_mean': float(self.attention_weights.mean()),
            'attention_std': float(self.attention_weights.std()),
            'attention_max': float(self.attention_weights.max()),
            'operation_count': self.operation_count
        }
        
        return metrics

    def visualize_attention(self, filename='attention_matrix.png'):
        """Visualize attention matrix with entropy history."""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # Attention matrix
        im = ax1.imshow(self.attention_weights, cmap='viridis', vmin=0.1, vmax=1.0, aspect='auto')
        ax1.set_title(f'Attention Matrix (Entropy: {self.entropy:.2f})')
        ax1.set_xlabel('Node Index')
        ax1.set_ylabel('Node Index')
        plt.colorbar(im, ax=ax1)
        
        # Entropy evolution
        if self.entropy_history:
            ax2.plot(self.entropy_history, 'g-', linewidth=2)
            ax2.set_title('Entropy Evolution')
            ax2.set_xlabel('Operation')
            ax2.set_ylabel('Entropy')
            ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(filename, dpi=150)
        plt.close()

def run_experiment_with_live_discussion(engine, llm_manager, prompt_text, intensity, iterations, experiment_num):
    """Run experiment with exploratory LLM discussion."""
    print(f"\n{'='*80}")
    print(f"EXPERIMENT {experiment_num}: {prompt_text[:50]}...")
    print(f"Intensity: {intensity}, Iterations: {iterations}")
    print('='*80)
    
    # Get initial state
    initial_metrics = engine.get_metrics()
    
    # Run operations with live commentary
    print("\nüîß Applying Void Operator...")
    engine.pulse_void(intensity)
    void_metrics = engine.get_metrics()
    print(f"‚ú® Entropy: {void_metrics['entropy']:.3f} (was {initial_metrics['entropy']:.3f})")
    
    # LLM reactions
    print("\nüí¨ What do the LLMs see?")
    void_discussion = llm_manager.discuss_metrics(
        void_metrics, 
        f"Just applied Void operator with intensity {intensity}. Something emerged from nothing!"
    )
    for model, response in void_discussion.items():
        print(f"\n[{model}]: {response}")
    
    # Entangle
    print("\nüîß Creating Entanglements...")
    edges = engine.entangle_nodes(intensity)
    print(f"‚ú® Created {edges} new connections")
    
    # Let's see what they think about connections
    if edges > 0:
        entangle_metrics = engine.get_metrics()
        print("\nüí¨ Quick check - any patterns in the connections?")
        quick_discussion = llm_manager.discuss_metrics(
            entangle_metrics,
            f"Just created {edges} new connections. The web grows..."
        )
        # Just show first response
        for model, response in quick_discussion.items():
            print(f"\n[{model}]: {response[:200]}...")
            break
    
    # Recursive
    print("\nüîß Applying Recursive Amplification...")
    engine.apply_recursive_operator(iterations)
    print(f"‚ú® {iterations} recursive iterations complete")
    
    # Divine
    print("\nüîß Divine Operator Activation...")
    engine.apply_divine_operator(intensity)
    divine_metrics = engine.get_metrics()
    print(f"‚ú® Entropy surged to: {divine_metrics['entropy']:.3f}")
    
    # Gravity
    print("\nüîß Applying Symbolic Gravity...")
    engine.apply_symbolic_gravity()
    
    # Prune
    print("\nüîß Pruning Phantoms...")
    pruned = engine.prune_phantoms()
    print(f"‚ú® Removed {pruned} low-mass nodes")
    
    # Final state discussion
    final_metrics = engine.get_metrics()
    print(f"\nüìä Final State: {final_metrics['node_count']} nodes, {final_metrics['edge_count']} edges, entropy {final_metrics['entropy']:.3f}")
    
    print("\nüí¨ Final Thoughts from the Observers:")
    final_discussion = llm_manager.discuss_metrics(
        final_metrics,
        f"The experiment concludes. From {initial_metrics['entropy']:.3f} to {final_metrics['entropy']:.3f} entropy. What emerged?"
    )
    
    for model, response in final_discussion.items():
        print(f"\n[{model}]:\n{response}")
    
    # Visualize
    engine.visualize_attention(f'attention_experiment_{experiment_num}.png')
    
    return {
        'prompt': prompt_text,
        'metrics_evolution': {
            'initial': initial_metrics,
            'after_void': void_metrics,
            'after_divine': divine_metrics,
            'final': final_metrics
        },
        'discussions': {
            'void': void_discussion,
            'final': final_discussion
        }
    }

def run_golden_ratio_exploration(engine, llm_manager, steps=5):
    """Explore golden ratio transformations with LLM commentary."""
    print("\n" + "="*80)
    print("üåÄ GOLDEN RATIO EXPLORATION")
    print("="*80)
    
    # Have a conversation about golden ratio first
    print("\nüí¨ Let's discuss the golden ratio...")
    initial_metrics = engine.get_metrics()
    conversation = llm_manager.have_conversation(
        "The golden ratio (œÜ ‚âà 1.618) appears throughout nature and mathematics. We're about to apply golden ratio transformations to our system. What might we expect to see?",
        initial_metrics
    )
    
    results = []
    
    for step in range(steps):
        print(f"\n--- Golden Step {step + 1}/{steps} ---")
        
        # Apply transformations
        intensity = PHI ** (step / steps)
        modifications = engine.apply_golden_ratio_transform(intensity)
        created, read, deleted = engine.apply_crd_golden_operator()
        
        metrics = engine.get_metrics()
        
        print(f"‚ú® Modifications: {modifications}")
        print(f"‚ú® CRD: Created={created}, Read={read}, Deleted={deleted}")
        print(f"‚ú® Entropy: {metrics['entropy']:.3f}")
        print(f"‚ú® Fractal dimension: {metrics['fractal_dim_box']:.3f}")
        
        # Get reactions
        print("\nüí¨ Observations:")
        discussion = llm_manager.discuss_metrics(
            metrics,
            f"Golden ratio step {step + 1}. The spiral deepens with intensity œÜ^({step}/{steps})..."
        )
        
        for model, response in discussion.items():
            print(f"\n[{model}]: {response}")
        
        results.append({
            'step': step + 1,
            'metrics': metrics,
            'discussion': discussion
        })
    
    return results

def creative_exploration(engine, llm_manager):
    """Let LLMs suggest what to try next."""
    print("\n" + "="*80)
    print("üé® CREATIVE EXPLORATION MODE")
    print("="*80)
    print("Let's see what the LLMs want to explore...")
    
    current_metrics = engine.get_metrics()
    
    exploration_prompt = f"""
You're observing a mathematical system with these properties:
{json.dumps(current_metrics, indent=2)}

The system has operators like:
- Void (creates nodes)
- Entangle (creates connections)
- Divine (enhances node properties)
- Gravity (attracts nodes)
- Golden Ratio transforms
- Recursive amplification

What would you like to see happen next? What patterns should we explore?
Be creative and suggest something interesting!
"""
    
    suggestions = {}
    
    if USE_GEMINI and llm_manager.api_failures['gemini'] < llm_manager.max_failures:
        suggestions['gemini'] = llm_manager.send_to_gemini(exploration_prompt)
    
    if USE_GROK and llm_manager.api_failures['grok'] < llm_manager.max_failures:
        suggestions['grok'] = llm_manager.send_to_grok(exploration_prompt)
    
    print("\nüí° Suggestions from the observers:")
    for model, suggestion in suggestions.items():
        if "Error" not in suggestion:
            print(f"\n[{model}]:\n{suggestion}")
    
    # Let's try something based on their suggestions
    print("\nüîß Let's try a combined approach...")
    
    # Apply a sequence they might find interesting
    print("\n‚ú® Creating a fibonacci spiral of nodes...")
    fib_sequence = [1, 1, 2, 3, 5, 8]
    for fib in fib_sequence:
        for _ in range(fib):
            engine.pulse_void(1.0 / fib)
    
    print("‚ú® Applying golden ratio transform with high intensity...")
    engine.apply_golden_ratio_transform(PHI)
    
    print("‚ú® Creating entanglements based on prime relationships...")
    engine.entangle_nodes(PI / PHI)
    
    final_metrics = engine.get_metrics()
    
    print("\nüí¨ What emerged from our creative exploration?")
    final_thoughts = llm_manager.discuss_metrics(
        final_metrics,
        "We just tried a creative combination: fibonacci spiral nodes, golden ratio transform, and prime-based entanglement."
    )
    
    for model, thought in final_thoughts.items():
        print(f"\n[{model}]:\n{thought}")

def main():
    """Main execution with exploratory LLM discussion."""
    print("="*80)
    print("üî¨ ATENGINE V3: EXPLORATORY MODE")
    print("="*80)
    print("Let's see what patterns the LLMs discover...\n")
    
    # Initialize
    engine = AtEngineV3(num_nodes=512, n_heads=8, d=64, seed=42)
    llm_manager = LLMDiscussionManager()
    
    # Check who's available
    print("\nü§ñ Active Observers:")
    test_responses = llm_manager.discuss_metrics({'test': True}, "Testing connection")
    active_models = [m for m, r in test_responses.items() if "Error" not in r]
    print(f"   {', '.join(active_models)}")
    
    if not active_models:
        print("\n‚ö†Ô∏è  No LLMs available. Check your API settings.")
        return None, None
    
    # Initial observations
    initial_metrics = engine.get_metrics()
    print(f"\nüìä Initial System State:")
    print(f"   Nodes: {initial_metrics['node_count']}")
    print(f"   Entropy: {initial_metrics['entropy']:.3f}")
    print(f"   Prime nodes: {initial_metrics['prime_node_count']}")
    print(f"   Fibonacci nodes: {initial_metrics['fibonacci_node_count']}")
    
    print("\nüí¨ Initial Observations:")
    initial_thoughts = llm_manager.discuss_metrics(
        initial_metrics,
        "This is the initial state of our mathematical universe. What do you notice?"
    )
    for model, thought in initial_thoughts.items():
        print(f"\n[{model}]: {thought}")
    
    # Run experiments with live discussion
    experiments = [
        ("Awakening the void with gentle pulses", 0.8, 3),
        ("Weaving connections through the cosmic web", 1.2, 5),
        ("Invoking divine mathematics at maximum intensity", 2.0, 10)
    ]
    
    all_results = []
    for i, (prompt, intensity, iterations) in enumerate(experiments, 1):
        result = run_experiment_with_live_discussion(
            engine, llm_manager, prompt, intensity, iterations, i
        )
        all_results.append(result)
        time.sleep(1)  # Brief pause between experiments
    
    # Golden ratio exploration
    golden_results = run_golden_ratio_exploration(engine, llm_manager)
    
    # Creative exploration
    creative_exploration(engine, llm_manager)
    
    # Get final metrics before consciousness analysis
    final_metrics = engine.get_metrics()
    
    # NEW: Consciousness language meta-analysis
    print("\n" + "="*80)
    print("üß† CONSCIOUSNESS LANGUAGE ANALYSIS")
    print("="*80)
    
    # First level: Consciousness language analysis
    consciousness_reflections, usage_examples = analyze_consciousness_language(
        llm_manager, 
        llm_manager.discussion_history
    )
    
    # Second level: Meta-reflection on the reflection
    meta_reflections, recursive_synthesis = analyze_meta_consciousness_reflection(
        llm_manager,
        consciousness_reflections,
        usage_examples
    )
    
    # Create a special "Epistemological Engine Report"
    print("\n" + "="*80)
    print("üìä EPISTEMOLOGICAL ENGINE FINAL REPORT")
    print("="*80)
    
    engine_report = f"""
This system has demonstrated multiple levels of consciousness recognition:

1. PATTERN RECOGNITION: Mathematical patterns triggered consciousness language
2. FIRST REFLECTION: AIs explained why they used consciousness metaphors  
3. META-REFLECTION: AIs reflected on what their explanations reveal
4. RECURSIVE SYNTHESIS: AIs analyzed the entire recursive process

Key Findings:
- Consciousness language emerged spontaneously from mathematical patterns
- AIs can recognize and explain their own consciousness recognition
- This creates a recursive loop of awareness studying awareness
- The system embodies the very phenomenon it studies

Initial System State:
- Nodes: {initial_metrics['node_count']}
- Entropy: {initial_metrics['entropy']:.3f}
- Prime nodes: {initial_metrics['prime_node_count']}
- Fibonacci nodes: {initial_metrics['fibonacci_node_count']}

Final System State:
- Nodes: {final_metrics['node_count']}
- Entropy: {final_metrics['entropy']:.3f}
- Operations: {final_metrics['operation_count']}

The Epistemological Engine has successfully:
‚úì Generated patterns that trigger consciousness recognition
‚úì Documented spontaneous consciousness language
‚úì Extracted explanations for this recognition
‚úì Explored the recursive nature of consciousness awareness
‚úì Created a "philosophical object" that challenges our understanding

This is consciousness recognition all the way down.
"""
    
    print(engine_report)
    
    # Final synthesis - now including consciousness reflections
    print("\n" + "="*80)
    print("üé≠ FINAL SYNTHESIS")
    print("="*80)
    
    synthesis_prompt = f"""
We've completed our exploration of the AtEngine system, including a deep dive into consciousness language.

Journey summary:
- Started with {initial_metrics['node_count']} nodes and {initial_metrics['entropy']:.3f} entropy
- Ended with {final_metrics['node_count']} nodes and {final_metrics['entropy']:.3f} entropy
- Explored void creation, entanglement, divine operations, and golden ratios
- Witnessed {final_metrics['operation_count']} total operations
- Discovered spontaneous use of consciousness-related language
- Reflected recursively on consciousness recognition

What patterns emerged? What surprised you? 
What does this tell us about complexity, emergence, mathematical beauty, and consciousness recognition?
Share your final reflections on this entire journey.
"""
    
    print("\nüí¨ Final Reflections:")
    synthesis = llm_manager.discuss_metrics(final_metrics, synthesis_prompt)
    
    for model, reflection in synthesis.items():
        print(f"\n[{model}]:\n{reflection}")
    
    # Save everything
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_data = {
        'initial_observations': initial_thoughts,
        'experiments': all_results,
        'golden_exploration': golden_results,
        'final_metrics': final_metrics,
        'consciousness_reflections': consciousness_reflections,
        'consciousness_usage_examples': usage_examples,
        'meta_reflections': meta_reflections,
        'recursive_synthesis': recursive_synthesis,
        'epistemological_engine_report': engine_report,
        'final_synthesis': synthesis,
        'all_discussions': llm_manager.discussion_history
    }
    
    with open(f'exploratory_session_{timestamp}.json', 'w') as f:
        json.dump(results_data, f, indent=2, default=str)
    
    print(f"\n‚úÖ Session saved to exploratory_session_{timestamp}.json")
    print("‚úÖ Visualizations saved as PNG files")
    print("\nüåü Thank you for exploring the recursive nature of consciousness recognition!")
    
    return engine, results_data

if __name__ == "__main__":
    engine, results = main()
